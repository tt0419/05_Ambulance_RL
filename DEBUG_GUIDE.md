# PPOハイブリッドモデル問題診断ガイド

## 概要

PPOハイブリッドモデルの性能が直近隊より劣る問題を診断するための3段階デバッグツールです。

**観察された問題:**
- 同一データ（6月15日）で500回学習後も性能が悪い
- 軽症系：14.64分（PPO） vs 7.50分（直近隊）
- 重症系：8.49分（PPO） vs 7.37分（直近隊）
- ハイブリッドなのに両方で性能が劣る

## デバッグツール一覧

### Phase 1: ID対応表の検証
**ファイル:** `debug_id_mapping.py`

**目的:** 
- ID対応表（`id_mapping_proposal.json`）の存在確認
- ValidationSimulatorとのID一致率確認
- 未マッピングIDの特定

**実行:**
```bash
python debug_id_mapping.py
```

**期待される診断結果:**
1. ✅ **マッピング率 100%**: ID対応表は完璧 → Phase 2へ
2. ⚠️  **マッピング率 80-99%**: 一部未マッピング → 修正してPhase 2へ
3. ❌ **マッピング率 < 80%**: 重大な問題 → まず修正が必要

**主な出力:**
```
📊 マッピング統計:
   ValidationSimulator救急車数: 192台
   マッピング済み: 150台
   マッピング率: 78.1%
   未マッピング: 42台
   余剰マッピング: 0台

🔍 診断結果:
   ❌ 重大: 多数の救急車が未マッピングです
   この状態ではPPO戦略の精度が大幅に低下します
```

**問題が見つかった場合の対処:**
```bash
# ID対応表を再生成
python phase1_id_validation.py

# または、救急車フィルタリングを統一
# ems_environment.py と validation_simulation.py で同じ除外条件を適用
```

---

### Phase 2: 1エピソード完全トレース
**ファイル:** `debug_single_episode_full.py`

**目的:**
- 6月15日データで1エピソード実行
- PPO vs 直近隊の使用回数と応答時間を比較
- フォールバックの発生頻度確認

**実行:**
```bash
python debug_single_episode_full.py
```

**期待される診断結果:**
1. **ハイブリッドロジックが正常動作**:
   - 重症系: 100% 直近隊運用
   - 軽症系: 100% PPO運用
   
2. **PPOが実際に呼ばれている**:
   - PPO使用回数 > 0
   - フォールバック回数 = 0（理想）

3. **応答時間の比較**:
   - PPO vs 直近隊の差分を定量化

**主な出力:**
```
シミュレーション結果サマリー
================================================================================

総事案数: 234件

全体平均応答時間: 9.82 ± 4.51分

傷病度別平均応答時間:
  軽症: 14.64 ± 5.23分 (n=120)
  中等症: 12.31 ± 4.87分 (n=80)
  重症: 8.49 ± 3.12分 (n=28)
  重篤: 7.85 ± 2.95分 (n=6)

ハイブリッドモード統計
--------------------------------------------------------------------------------
直近隊運用: 34回
PPO運用: 200回
直近隊比率: 14.5%

比較結果:
--------------------------------------------------------------------------------
傷病度別比較:
  軽症: PPO=14.64分 vs 直近隊=7.50分 (+7.14分, +95.2%) ❌
  中等症: PPO=12.31分 vs 直近隊=8.32分 (+3.99分, +48.0%) ❌
  重症: PPO=8.49分 vs 直近隊=7.37分 (+1.12分, +15.2%) ⚠️
```

**問題パターンと対処:**

1. **PPO使用回数 = 0 または 極端に少ない**
   ```
   → ハイブリッドロジックに問題
   → dispatch_strategies.py:1006-1020 を確認
   ```

2. **フォールバック回数が多い**
   ```
   → ID対応表の問題（Phase 1に戻る）
   ```

3. **PPOは呼ばれているが性能が悪い**
   ```
   → Phase 3で詳細調査
   ```

---

### Phase 3: PPO入出力詳細トレース
**ファイル:** `debug_ppo_io_trace.py`

**目的:**
- PPOの状態ベクトル内容確認
- 行動選択プロセスの可視化
- 選択された救急車の妥当性確認
- 直近隊との比較

**実行:**
```bash
python debug_ppo_io_trace.py
```

**期待される診断結果:**
1. **最適解一致率**:
   - 90%以上: PPOは良好に動作
   - 50-90%: 改善の余地あり
   - 50%未満: 重大な問題

2. **応答時間差分**:
   - 平均差分が大きい場合、モデルの問題

**主な出力:**
```
事案 #42: 軽症
================================================================================
✅ 軽症系事案 → PPO学習対象

--- Step 1: 状態ベクトル構築 ---
状態辞書:
  救急車数: 192台
  事案: 軽症 @ 891f1d4347fffff
  時刻: ステップ42, 12時

状態ベクトル:
  形状: (999,)
  最小値: -2.134
  最大値: 3.456
  平均値: 0.012
  非ゼロ要素数: 823/999

--- Step 2: 行動マスク作成 ---
行動マスク:
  True数: 98/192
  利用可能な行動率: 51.0%
  有効な行動インデックス（最初の10個）: [0, 2, 5, 7, 9, 12, 15, 18, 21, 24]

--- Step 3: PPO行動選択 ---
PPO出力:
  選択された行動: 45
  対数確率: -2.3456
  価値推定: 12.34
  行動は有効?: ✅

--- Step 4: 行動→救急車マッピング ---
✅ マッピング成功:
  救急車ID: 港_2
  位置: 891f1d4347fffff
  状態: available

--- Step 5: 応答時間計算 ---
PPO選択:
  救急車: 港_2
  応答時間: 15.23分

--- Step 6: 直近隊との比較 ---
直近隊:
  救急車: 芝_0
  応答時間: 7.45分

⚠️  PPOは直近隊ではない救急車を選択
   差分: +7.78分 (+104.4%)

================================================================================

トレースサマリー
================================================================================

PPO使用事案: 10件

最適解一致率: 20.0% (2/10件)

応答時間:
  PPO平均: 14.52分
  直近隊平均: 7.83分
  差分: +6.69分

⚠️  最悪ケース（上位5件）:
  1. 事案#42: 軽症, 差分=+7.78分 (PPO: 港_2, 最適: 芝_0)
  2. 事案#58: 中等症, 差分=+6.45分 (PPO: 新宿_1, 最適: 四谷_0)
  ...
```

**問題パターンと対処:**

1. **最適解一致率 < 50%**
   ```
   → モデルの学習不足、または報酬設計の問題
   → 学習を継続、または報酬関数を見直し
   ```

2. **マッピング失敗が頻発**
   ```
   ❌ マッピング失敗: 行動45に対応する救急車が見つからない
   → ID対応表の問題（Phase 1に戻る）
   ```

3. **行動マスクのTrue数が極端に少ない**
   ```
   行動マスク: True数: 5/192
   → 初期状態で多数の救急車がbusyの問題
   → 学習データの問題、または環境設定の問題
   ```

4. **状態ベクトルに異常値**
   ```
   最小値: -999.0, 最大値: 999.0
   → StateEncoderの正規化に問題
   → 学習時と推論時で正規化パラメータが異なる可能性
   ```

---

## 診断フローチャート

```
START
  ↓
[Phase 1] debug_id_mapping.py
  ↓
  マッピング率 < 80%? ─YES→ ID対応表を修正 → 再実行
  ↓ NO
[Phase 2] debug_single_episode_full.py
  ↓
  PPO使用回数 = 0? ─YES→ ハイブリッドロジック修正 → 再実行
  ↓ NO
  フォールバック多発? ─YES→ Phase 1に戻る
  ↓ NO
[Phase 3] debug_ppo_io_trace.py
  ↓
  マッピング失敗多発? ─YES→ Phase 1に戻る
  ↓ NO
  最適解一致率 < 50%? ─YES→ モデル再学習 or 報酬設計見直し
  ↓ NO
  応答時間差分大? ─YES→ モデルの問題を詳細調査
  ↓
END
```

---

## 最も疑わしい問題（優先度順）

### 1. ⭐⭐⭐ ID対応表の欠落または不一致（最重要）
**症状:**
- `id_mapping_proposal.json` が存在しない
- マッピング率 < 100%
- フォールバックモードで動作

**対処:**
```bash
# ID対応表を再生成
python phase1_id_validation.py

# 救急車フィルタリングの統一確認
# ems_environment.py:_load_base_data()
# validation_simulation.py:__init__()
# 両方で同じ除外条件を適用
```

**確認方法:**
```bash
python debug_id_mapping.py
```

---

### 2. ⭐⭐ 初期利用可能隊数の影響
**症状:**
- 行動マスクのTrue数が極端に少ない
- 初期状態で4-6割の救急車がbusy

**対処:**
- 学習データの見直し
- 初期状態の設定確認
- エピソード開始時刻のランダム化

**確認方法:**
```bash
python debug_ppo_io_trace.py
# 行動マスクのTrue数を確認
```

---

### 3. ⭐ 学習時と推論時の状態エンコーディング不一致
**症状:**
- 状態ベクトルに異常値
- 正規化パラメータの不一致

**対処:**
- StateEncoderの正規化パラメータを確認
- 学習時と推論時で同じパラメータを使用

**確認方法:**
```bash
python debug_ppo_io_trace.py
# 状態ベクトルの値の範囲を確認
```

---

## トラブルシューティング

### エラー: `id_mapping_proposal.json` が見つかりません

```bash
# Phase 1を実行してID対応表を生成
python phase1_id_validation.py
```

### エラー: モジュールのインポートエラー

```bash
# 必要なモジュールがインストールされているか確認
pip install -r requirements.txt

# プロジェクトルートから実行しているか確認
pwd  # プロジェクトルートにいることを確認
```

### エラー: PPOモデルファイルが見つかりません

```python
# debug_ppo_io_trace.py の model_path を確認
model_path = 'reinforcement_learning/experiments/ppo_training/ppo_20251017_113908/final_model.pth'

# 実際のモデルファイルパスに変更
```

---

## まとめ

このデバッグガイドに従って、以下の順序で問題を特定してください：

1. **Phase 1** でID対応表の問題を確認・修正
2. **Phase 2** でハイブリッドロジックとPPO使用状況を確認
3. **Phase 3** でPPOの詳細動作を確認

各Phaseで問題が見つかった場合、その場で修正してから次のPhaseに進んでください。

**最も可能性の高い原因:**
- ID対応表の欠落（約70%の確率）
- 初期利用可能隊数の問題（約20%の確率）
- その他（約10%の確率）

問題が特定できたら、適切な修正を行い、再度学習または評価を実行してください。

