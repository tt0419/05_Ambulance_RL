# ================================================================
# 基本設定ファイル
# システムの動作に必要な基本設定を記載
# 実験ごとの変更はconfig_tokyo23.yamlで行う
# ================================================================

# ================================================================
# 実験基本設定（デフォルト値）
# ================================================================
experiment:
  name: "ppo_dispatch_optimization"
  description: "救急車配車最適化"
  seed: 42
  device: "cuda"  # "cpu" or "cuda"

# ================================================================
# データ基本設定
# ================================================================
data:
  # データパス（システム必須）
  data_paths:
    grid_mapping: "data/tokyo/processed/grid_mapping_res9.json"
    travel_time_matrix: "data/tokyo/calibration2/linear_calibrated_response.npy"
  
  # シミュレーション設定
  episode_duration_hours: 24
  
  # デフォルトのエリア設定（個別設定で上書き）
  area_restriction:
    enabled: false
    area_name: "default"
    districts: []
    num_ambulances_in_area: 100
    state_dim: 527
    action_dim: 100
  
  # デフォルト期間（個別設定で上書き）
  train_periods:
    - start_date: "20230401"
      end_date: "20230430"
  eval_periods:
    - start_date: "20230501"
      end_date: "20230507"

# ================================================================
# 傷病度定義（システム固定）
# ================================================================
severity:
  categories:
    critical:
      conditions: ["重症", "重篤", "死亡"]
      time_limit_seconds: 360  # 6分
      reward_weight: 5.0
    moderate:
      conditions: ["中等症"]
      time_limit_seconds: 780  # 13分
      reward_weight: 2.0
    mild:
      conditions: ["軽症"]
      time_limit_seconds: 780  # 13分
      reward_weight: 1.0
  
  thresholds:
    golden_time: 360    # 6分（重症系目標）
    standard_time: 780  # 13分（全体目標）

# ================================================================
# PPOデフォルト設定（個別設定で上書き可能）
# ================================================================
ppo:
  # 基本パラメータ（個別設定のデフォルトと同じ値）
  n_episodes: 5000
  batch_size: 1024
  n_epochs: 6
  clip_epsilon: 0.1
  
  # 学習率（個別設定のデフォルトと同じ値）
  learning_rate:
    actor: 0.0003
    critic: 0.001
    scheduler: "constant"
  
  # アルゴリズムパラメータ（通常変更しない）
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.015
  max_grad_norm: 0.5

# ================================================================
# 報酬システム設定（内部構造）
# ================================================================
reward:
  # システムレベル（環境の基本動作）
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0
  
  # コア設定（個別設定のreward_modeで制御）
  core:
    mode: "simple"  # デフォルト値（個別設定で上書き）
    
    # 各モードのデフォルト値（個別設定と同じ）
    simple_params:
      time_penalty_per_minute: -0.5
      critical_under_6min_bonus: 30.0
      moderate_under_13min_bonus: 10.0
      mild_under_13min_bonus: 5.0
      over_13min_penalty: -5.0
      over_20min_penalty: -20.0
      imitation_bonus: 0.0  # 教師なしなのでデフォルト0
    
    continuous_params:
      critical:
        target: 6
        max_bonus: 50.0
        penalty_scale: 5.0
        weight: 5.0
      moderate:
        target: 13
        max_bonus: 20.0
        penalty_scale: 2.0
        weight: 2.0
      mild:
        target: 13
        max_bonus: 10.0
        penalty_scale: 0.5
        weight: 1.0
    
    discrete_params:
      weights:
        response_time: 2.0
        severity_bonus: 3.0
        coverage_preservation: 0.5
      penalties:
        over_6min: -10.0
        over_13min: -15.0
        per_minute_over: -2.0
    
    # ハイブリッドモード用パラメータ
    hybrid_params:
      time_penalty_per_minute: -0.3
      mild_under_13min_bonus: 5.0
      moderate_under_13min_bonus: 10.0
      over_13min_penalty: -5.0
      over_20min_penalty: -50.0
      good_coverage_bonus: 10.0
      coverage_maintenance_bonus: 5.0
      poor_coverage_penalty: -10.0
      balanced_workload_bonus: 2.0
      overloaded_penalty: -5.0
    
    # カバレッジ影響（デフォルト無効）
    coverage_impact_weight: 0.0
  
  # カバレッジパラメータ（デフォルト値）
  coverage_params:
    time_threshold_seconds: 600
    drop_penalty_threshold: 0.05
    drop_penalty_weight: -20.0
  
  # エピソードレベル報酬
  episode:
    base_penalty_per_minute: -0.5
    achievement_bonuses:
      rate_6min: 20.0
      rate_13min: 10.0
      critical_6min_rate: 30.0
    failure_penalty_per_incident: -1.0

# ================================================================
# ネットワーク構造（通常変更しない）
# ================================================================
network:
  # 状態エンコーダ
  state_encoder:
    ambulance_features: 8
    incident_features: 6
    spatial_features: 16
    temporal_features: 8
  
  # Actor/Criticネットワーク
  actor:
    hidden_layers: [256, 128]
    activation: "relu"
    initialization: "xavier_uniform"
    dropout: 0.1
  
  critic:
    hidden_layers: [256, 128]
    activation: "relu"
    init_scale: 0.001
    dropout: 0.1

# ================================================================
# 学習管理（通常変更しない）
# ================================================================
training:
  checkpoint_interval: 250
  keep_last_n: 5
  
  early_stopping:
    enabled: true
    patience: 500
    min_delta: 0.001
  
  logging:
    interval: 10
    tensorboard: true
    wandb: true

# ================================================================
# 評価設定デフォルト（個別設定で上書き）
# ================================================================
evaluation:
  interval: 100
  n_eval_episodes: 10
  compare_baselines: ["closest"]
  metrics:
    - "critical_6min_rate"
    - "achieved_13min_rate"
    - "mean_response_time"
    - "vs_closest_improvement"

# ================================================================
# オプション機能デフォルト（個別設定で制御）
# ================================================================
# 教師あり学習（デフォルト無効）
teacher:
  enabled: false
  strategy: "closest"
  initial_prob: 0.5
  final_prob: 0.05
  decay_episodes: 2500

# カリキュラム学習（デフォルト無効）
curriculum:
  enabled: false
  stages: []

# ハイブリッドモード（デフォルト無効）
hybrid_mode:
  enabled: false
  severity_classification:
    severe_conditions: ["重症", "重篤", "死亡"]
    mild_conditions: ["軽症", "中等症"]
  reward_weights:
    response_time: 0.4
    coverage: 0.5
    workload_balance: 0.1
  time_thresholds:
    good: 13
    warning: 20
  penalties:
    over_warning: -50.0
    per_minute_over: -2.0
  coverage_evaluation:
    high_risk_weight: 0.7
    normal_weight: 0.3
    min_acceptable: 0.6