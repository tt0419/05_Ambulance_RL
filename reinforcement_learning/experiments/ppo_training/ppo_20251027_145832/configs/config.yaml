curriculum:
  enabled: false
  stages: []
data:
  area_restriction:
    area_name: default
    districts: []
    enabled: false
    num_ambulances_in_area: 192
  data_paths:
    grid_mapping: data/tokyo/processed/grid_mapping_res9.json
    travel_time_matrix: data/tokyo/calibration2/linear_calibrated_response.npy
  episode_duration_hours: 24
  eval_periods:
  - end_date: '20240831'
    start_date: '20240701'
  exclude_daytime_ambulances: true
  train_periods:
  - end_date: '20230831'
    start_date: '20230701'
  - end_date: '20240130'
    start_date: '20231201'
evaluation:
  compare_baselines:
  - closest
  - severity_based
  eval_deterministic: false
  interval: 5
  metrics:
  - critical_6min_rate
  - achieved_13min_rate
  - mean_response_time
  - critical_mean_time
  n_eval_episodes: 5
experiment:
  description: 救急車配車最適化
  device: cuda
  name: ppo_continuous_reward_busydays78-121-78_test
  seed: 42
hybrid_mode:
  coverage_evaluation:
    high_risk_weight: 0.7
    min_acceptable: 0.6
    normal_weight: 0.3
  enabled: false
  penalties:
    over_warning: -50.0
    per_minute_over: -2.0
  reward_weights:
    coverage: 0.5
    response_time: 0.4
    workload_balance: 0.1
  severity_classification:
    mild_conditions:
    - 軽症
    - 中等症
    severe_conditions:
    - 重症
    - 重篤
    - 死亡
  time_thresholds:
    good: 13
    warning: 20
metadata:
  author: 研究者名
  date: '2025-01-20'
  description: 連続報酬関数による重症案件RT短縮実験
  notes: '- 重症の6分到達率向上を最優先

    - 軽症・中等症のRTは許容範囲内で犠牲可

    - 連続報酬により滑らかな学習を期待'
network:
  actor:
    activation: relu
    dropout: 0.1
    hidden_layers:
    - 256
    - 128
    initialization: xavier_uniform
  critic:
    activation: relu
    dropout: 0.1
    hidden_layers:
    - 256
    - 128
    init_scale: 0.001
  state_encoder:
    ambulance_features: 8
    incident_features: 6
    spatial_features: 16
    temporal_features: 8
ppo:
  batch_size: 1024
  clip_epsilon: 0.2
  entropy_coef: 0.1
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate:
    actor: 0.0003
    critic: 0.001
    scheduler: cosine
  max_grad_norm: 0.5
  n_episodes: 50
  n_epochs: 6
  target_kl: 0.02
  value_loss_coeff: 0.5
reward:
  continuous_params:
    critical:
      max_bonus: 100
      penalty_scale: 3.0
      target: 6
    mild:
      max_bonus: 10
      penalty_scale: 3.0
      target: 10
    moderate:
      max_bonus: 30
      penalty_scale: 5.0
      target: 10
  core:
    continuous_params:
      critical:
        max_bonus: 50.0
        penalty_scale: 5.0
        target: 6
        weight: 5.0
      mild:
        max_bonus: 10.0
        penalty_scale: 0.5
        target: 13
        weight: 1.0
      moderate:
        max_bonus: 20.0
        penalty_scale: 2.0
        target: 13
        weight: 2.0
    coverage_impact_weight: 0.0
    discrete_params:
      penalties:
        over_13min: -15.0
        over_6min: -10.0
        per_minute_over: -2.0
      weights:
        coverage_preservation: 0.5
        response_time: 2.0
        severity_bonus: 3.0
    hybrid_params:
      balanced_workload_bonus: 2.0
      coverage_maintenance_bonus: 5.0
      good_coverage_bonus: 10.0
      mild_under_13min_bonus: 5.0
      moderate_under_13min_bonus: 10.0
      over_13min_penalty: -5.0
      over_20min_penalty: -50.0
      overloaded_penalty: -5.0
      poor_coverage_penalty: -10.0
      time_penalty_per_minute: -0.3
    mode: simple
    simple_params:
      critical_under_6min_bonus: 30.0
      imitation_bonus: 0.0
      mild_under_13min_bonus: 5.0
      moderate_under_13min_bonus: 10.0
      over_13min_penalty: -5.0
      over_20min_penalty: -20.0
      time_penalty_per_minute: -0.5
  coverage_params:
    drop_penalty_threshold: 0.05
    drop_penalty_weight: -20.0
    time_threshold_seconds: 600
  episode:
    achievement_bonuses:
      critical_6min_rate: 30.0
      rate_13min: 10.0
      rate_6min: 20.0
    base_penalty_per_minute: -0.5
    failure_penalty_per_incident: -1.0
  penalties:
    over_13min: -20.0
    over_6min: -5.0
    per_minute_over: -1.0
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0
  use_continuous: true
  weights:
    coverage_preservation: 0.5
    response_time: -1.0
    severity_bonus: 2.0
    threshold_penalty: -10.0
severity:
  categories:
    critical:
      conditions:
      - 重篤
      - 重症
      - 死亡
      reward_weight: 1.0
      time_limit_seconds: 360
    mild:
      conditions:
      - 軽症
      reward_weight: 1.0
      time_limit_seconds: 600
    moderate:
      conditions:
      - 中等症
      reward_weight: 1.0
      time_limit_seconds: 600
  thresholds:
    golden_time: 360
    standard_time: 600
teacher:
  decay_episodes: 1500
  enabled: false
  final_prob: 0.1
  initial_prob: 0.5
  strategy: closest
training:
  checkpoint_interval: 100
  early_stopping:
    enabled: true
    min_delta: 0.01
    min_episodes: 1000
    patience: 500
  keep_last_n: 10
  logging:
    interval: 10
    log_level: INFO
    tensorboard: true
    wandb: true
