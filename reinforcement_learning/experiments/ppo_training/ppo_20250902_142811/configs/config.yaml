curriculum:
  enabled: true
  stages:
  - description: 徹底的な模倣フェーズ。teacher_probは高水準 (0.99 -> 0.6) を維持。
    episodes:
    - 0
    - 1500
    goals:
    - vs_closest_improvement > -0.1
  - description: '模倣を続けつつ(teacher_prob: 0.6 -> 0.3)、重症事案での改善を探索。'
    episodes:
    - 1500
    - 3000
    goals:
    - critical_6min_rate > (baseline + 0.05)
    - achieved_13min_rate > (baseline - 0.02)
data:
  area_restriction:
    action_dim: 16
    area_name: 第一方面
    districts:
    - 千代田区
    - 中央区
    - 港区
    enabled: true
    num_ambulances_in_area: 16
    section_code: 1
    state_dim: 118
  episode_duration_hours: 24
  eval_periods:
  - end_date: '20240412'
    start_date: '20240408'
  train_periods:
  - end_date: '20230414'
    start_date: '20230410'
data_paths:
  grid_mapping: data/tokyo/processed/grid_mapping_res9.json
  travel_time_matrix: data/tokyo/calibration2/linear_calibrated_response.npy
evaluation:
  compare_baselines:
  - closest
  interval: 100
  metrics:
  - critical_6min_rate
  - achieved_13min_rate
  - mean_response_time
  - vs_closest_improvement
  n_eval_episodes: 10
experiment:
  description: さらにreward_designerの基準を6分から8分に変更、重症6分のボーナスを20に変更
  device: cuda
  name: ppo_area1_simple_reward_v1
  seed: 2025
inherits: ./config.yaml
network:
  actor:
    activation: relu
    dropout: 0.1
    hidden_layers:
    - 64
    - 32
    initialization: xavier_uniform
  critic:
    activation: relu
    dropout: 0.1
    hidden_layers:
    - 64
    - 32
    init_scale: 0.001
  state_encoder:
    ambulance_features: 8
    incident_features: 6
    spatial_features: 16
    temporal_features: 8
ppo:
  batch_size: 512
  clip_epsilon: 0.1
  entropy_coef: 0.015
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate:
    actor: 5.0e-05
    critic: 0.0001
    scheduler: constant
  max_grad_norm: 0.5
  n_episodes: 500
  n_epochs: 4
reward:
  core:
    continuous_params:
      critical:
        max_bonus: 50.0
        penalty_scale: 5.0
        target: 6
        weight: 5.0
      mild:
        max_bonus: 10.0
        penalty_scale: 0.5
        target: 13
        weight: 1.0
      moderate:
        max_bonus: 20.0
        penalty_scale: 2.0
        target: 13
        weight: 2.0
    coverage_impact_weight: 0.0
    discrete_params:
      penalties:
        over_13min: -15.0
        over_6min: -10.0
        per_minute_over: -2.0
      weights:
        coverage_preservation: 0.5
        response_time: 2.0
        severity_bonus: 3.0
    mode: simple
    simple_params:
      critical_under_6min_bonus: 10.0
      imitation_bonus: 0.5
      mild_under_13min_bonus: 2.0
      moderate_under_13min_bonus: 5.0
      over_13min_penalty: -2.0
      over_20min_penalty: -5.0
      time_penalty_per_minute: -0.25
  episode:
    achievement_bonuses:
      critical_6min_rate: 30.0
      rate_13min: 10.0
      rate_6min: 20.0
    base_penalty_per_minute: -0.5
    failure_penalty_per_incident: -2.0
  legacy:
    penalties:
      over_13min: -20.0
      over_6min: -5.0
      per_minute_over: -1.0
    weights:
      coverage_preservation: 0.5
      response_time: -1.0
      severity_bonus: 2.0
      threshold_penalty: -10.0
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0
severity:
  categories:
    critical:
      conditions:
      - 重症
      - 重篤
      - 死亡
      reward_weight: 5.0
      time_limit_seconds: 360
    mild:
      conditions:
      - 軽症
      reward_weight: 1.0
      time_limit_seconds: 780
    moderate:
      conditions:
      - 中等症
      reward_weight: 2.0
      time_limit_seconds: 480
  thresholds:
    golden_time: 360
    standard_time: 780
teacher:
  decay_episodes: 250
  enabled: true
  final_prob: 0.3
  initial_prob: 0.99
  strategy: closest
training:
  checkpoint_interval: 250
  early_stopping:
    enabled: true
    min_delta: 0.001
    patience: 500
  keep_last_n: 5
  logging:
    interval: 10
    tensorboard: true
    wandb: true
