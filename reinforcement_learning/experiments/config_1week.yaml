# 1週間学習設定
experiment:
  name: "ppo_1week_experiment"
  seed: 42
  device: "cuda"

data:
  train_periods:
    - start_date: "20230401"
      end_date: "20230407"
    - start_date: "20230410"
      end_date: "20230416"
    - start_date: "20230420"
      end_date: "20230426"
  
  eval_periods:
    - start_date: "20230408"
      end_date: "20230409"
    - start_date: "20230417"
      end_date: "20230419"
  
  episode_duration_hours: 12

severity:
  categories:
    critical:
      conditions: ["重篤", "重症", "死亡"]
      reward_weight: 5.0
    moderate:
      conditions: ["中等症"]
      reward_weight: 2.0
    mild:
      conditions: ["軽症"]
      reward_weight: 1.0

ppo:
  n_episodes: 200
  batch_size: 64
  learning_rate:
    actor: 0.0003
    critic: 0.0005
    scheduler: "linear"
  gamma: 0.99
  gae_lambda: 0.95
  clip_epsilon: 0.2
  entropy_coef: 0.01
  value_loss_coeff: 0.5
  max_grad_norm: 0.5
  n_epochs: 4
  target_kl: 0.01

network:
  actor:
    hidden_sizes: [512, 256, 128]
    activation: "tanh"
  critic:
    hidden_sizes: [512, 256, 128]
    activation: "tanh"
  state_encoder:
    ambulance_features: 4
    incident_features: 10
    spatial_features: 20
    temporal_features: 8

training:
  checkpoint_interval: 50
  early_stopping:
    enabled: true
    patience: 100
    min_delta: 10.0
  logging:
    tensorboard: false
    wandb: true
    log_level: "INFO"

evaluation:
  interval: 25
  n_eval_episodes: 10
  eval_deterministic: true

# 報酬関数設定（緩和版）
reward:
  weights:
    response_time: -0.5
    severity_bonus: 3.0
    threshold_penalty: -5.0
    coverage_preservation: 0.5
  penalties:
    over_6min: -2.5
    over_13min: -10.0
    per_minute_over: -0.5

# 教師あり学習設定
teacher:
  enabled: true
  initial_prob: 0.8
  final_prob: 0.2
  decay_episodes: 100