# PPO第1方面限定実験 - 閾値段階強化版
# 緩い基準から徐々に厳しくしていくアプローチ

experiment:
  name: ppo_area1_threshold_v1
  description: "第1方面での閾値を段階的に厳しくする学習"
  seed: 1111
  device: cpu

data:
  area_restriction:
    enabled: true
    area_name: 第一方面
    section_code: 1
    districts:
      - 千代田区
      - 中央区
      - 港区
  
  episode_duration_hours: 4
  
  train_periods:
    - start_date: "20230401"
      end_date: "20230407"
  
  eval_periods:
    - start_date: "20230408"
      end_date: "20230409"

ppo:
  n_episodes: 2000
  batch_size: 96
  
  # 安定した学習率
  learning_rate:
    actor: 0.00008
    critic: 0.00015
    scheduler: constant  # 一定に保つ
  
  n_epochs: 4
  clip_epsilon: 0.15
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.02
  value_loss_coeff: 1.0
  max_grad_norm: 0.5
  target_kl: 0.02

# 段階的な閾値設定（エピソード数で区切る）
threshold_curriculum:
  enabled: true
  stages:
    # Stage 1: 緩い基準（0-300エピソード）
    - episodes: [0, 300]
      thresholds:
        critical_target: 10    # 10分（緩い）
        moderate_target: 15    # 15分
        mild_target: 20        # 20分
        penalty_scale: 0.3     # ペナルティ緩め
      
    # Stage 2: 中間基準（300-600エピソード）
    - episodes: [300, 600]
      thresholds:
        critical_target: 8     # 8分
        moderate_target: 12    # 12分
        mild_target: 18        # 18分
        penalty_scale: 0.6
      
    # Stage 3: 標準基準（600-900エピソード）
    - episodes: [600, 900]
      thresholds:
        critical_target: 7     # 7分
        moderate_target: 10    # 10分
        mild_target: 15        # 15分
        penalty_scale: 0.8
      
    # Stage 4: 目標基準（900-1200エピソード）
    - episodes: [900, 2000]
      thresholds:
        critical_target: 6     # 6分（目標）
        moderate_target: 8     # 8分
        mild_target: 13        # 13分
        penalty_scale: 1.0

# 報酬設計（段階的閾値と連動）
reward:
  base_reward: 80.0  # 高めの基本報酬
  
  # 基本ペナルティ（段階的に調整される）
  penalties:
    over_6min: -1.5
    over_13min: -4.0
    per_minute_over: -0.08
  
  weights:
    response_time: -0.15
    severity_bonus: 12.0
    coverage_preservation: 0.05
    threshold_penalty: -1.5
  
  # 連続報酬（閾値は動的に変更）
  use_continuous: true
  continuous_params:
    # これらの値は threshold_curriculum で上書きされる
    critical:
      target: 10  # 初期値（Stage 1）
      max_bonus: 250
      penalty_scale: 1.5
    moderate:
      target: 15
      max_bonus: 80
      penalty_scale: 0.4
    mild:
      target: 20
      max_bonus: 25
      penalty_scale: 0.2

# 教師あり学習（段階的に減少）
teacher:
  enabled: true
  initial_prob: 0.90
  final_prob: 0.35
  decay_episodes: 800
  
  adaptive_recovery:
    enabled: true
    check_interval: 30
    min_performance: 0.35

# ネットワーク
network:
  actor:
    hidden_layers: [96, 48]  # 少し大きめ
    activation: relu  # ReLUに戻す
    dropout: 0.0
    
  critic:
    hidden_layers: [96, 48]
    activation: relu
    dropout: 0.0
    init_scale: 0.01
    
  state_encoder:
    ambulance_features: 4
    incident_features: 10
    temporal_features: 8
    spatial_features: 20

# 傷病度設定（固定）
severity:
  categories:
    critical:
      conditions: [重篤, 重症, 死亡]
      reward_weight: 25  # 重症系を最重視
      time_limit_seconds: 600  # 10分（初期）
      
    moderate:
      conditions: [中等症]
      reward_weight: 8
      time_limit_seconds: 900  # 15分（初期）
      
    mild:
      conditions: [軽症]
      reward_weight: 2
      time_limit_seconds: 1200  # 20分（初期）
      
  thresholds:
    golden_time: 600    # 10分（初期）
    standard_time: 900  # 15分（初期）

# 評価設定
evaluation:
  interval: 25
  n_eval_episodes: 5
  eval_deterministic: true
  
  # 段階別の期待性能
  stage_targets:
    stage_1:
      critical_10min_rate: 0.85  # 10分で85%（第1方面は都心部でアクセス良好）
      all_20min_rate: 0.98
    stage_2:
      critical_8min_rate: 0.75   # 8分で75%
      all_18min_rate: 0.95
    stage_3:
      critical_7min_rate: 0.65   # 7分で65%
      all_15min_rate: 0.90
    stage_4:
      critical_6min_rate: 0.50   # 6分で50%（第1方面目標）
      all_13min_rate: 0.90
  
  compare_baselines:
    - closest
    - severity_based
  
  metrics:
    - critical_6min_rate
    - achieved_13min_rate
    - mean_response_time
    - area1_specific_rate

training:
  checkpoint_interval: 50
  keep_last_n: 12
  
  # 段階移行時の処理
  stage_transition:
    reset_optimizer: false  # オプティマイザはリセットしない
    log_transition: true
    
  early_stopping:
    enabled: true
    patience: 400
    min_delta: 0.002
    min_episodes: 400
    
  logging:
    interval: 5
    log_level: INFO
    tensorboard: true
    wandb: true
    
    threshold_logs:
      - current_thresholds
      - stage_number
      - achievement_rates

advanced:
  # 追加の安定化機能
  gradient_clipping:
    method: global_norm
    max_norm: 0.5
    
  # 報酬の移動平均
  reward_smoothing:
    enabled: true
    window_size: 50
    
  # 経験の優先度付け
  experience_prioritization:
    enabled: true
    method: td_error  # TD誤差ベース
    
  debug:
    log_threshold_changes: true
    save_stage_checkpoints: true

metadata:
  description: |
    第1方面での閾値段階強化アプローチ
    - Stage 1 (0-300): 10分/15分/20分の緩い基準で基礎学習
    - Stage 2 (300-600): 8分/12分/18分の中間基準
    - Stage 3 (600-900): 7分/10分/15分の標準基準
    - Stage 4 (900-1200): 6分/8分/13分の目標基準
    
    第1方面（千代田区、中央区、港区）に限定した学習
    都心部の特性を活かした効率的な救急車配車を目指す
    
  notes: |
    - 第1方面（千代田区、中央区、港区）限定の実験
    - section=1の救急隊のみを使用
    - 都心部の高密度な病院配置を活用
    - 最初は「10分以内に到着」という緩い目標
    - 徐々に「6分以内」という厳しい目標へ
    - 各段階で十分な性能を確保してから次へ
    - 重症系の重みを高く設定（25倍）