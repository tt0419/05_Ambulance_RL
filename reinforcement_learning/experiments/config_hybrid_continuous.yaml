# config_hybrid_continuous.yaml
# 東京23区全域でのハイブリッドモード実験用設定ファイル
# continuousモードの報酬設計をハイブリッドモードに統合
# ベース: config_tokyo23_hybrid_continuous.yamlの設定を継承し、報酬設計を中心に簡素×改良化

# ベース設定ファイルを継承
inherits: ./config.yaml

# ===================================================================
# ハイブリッドモード戦略
# 重症系（重症・重篤・死亡）: 直近隊運用で確実に対応
# 軽症系（軽症・中等症）: PPO学習で効率的な配置を学習
# ===================================================================

# データパス設定（PPO戦略の初期化に必要）
data_paths:
  grid_mapping: "data/tokyo/processed/grid_mapping_res9.json"
  travel_time_matrix: "data/tokyo/calibration2/linear_calibrated_response.npy"

experiment:
  name: "hybrid_ppo_cont_oneday_v2"
  description: "報酬設計をシンプルかつ滑らかに変更"
  seed: 42
  device: cuda

# -------------------------------------------------------------------
# 報酬モード設定（reward_mode.modeで報酬計算モードを指定）
# -------------------------------------------------------------------
reward_mode:
  mode: hybrid  # hybridモードを使用

# -------------------------------------------------------------------
# ハイブリッドモード設定（ems_environment用）
# -------------------------------------------------------------------
hybrid_mode:
  enabled: true
  
  # 傷病度分類
  severity_classification:
    severe_conditions: ["重症", "重篤", "死亡"]  # 直近隊運用（学習対象外）
    mild_conditions: ["軽症", "中等症"]           # PPO学習対象
  
  # # ハイブリッドモード内の報酬重み付け
  # reward_weights:
  #   response_time: 0.7      # 応答時間重視（continuousの連続報酬を活かす）
  #   coverage: 0.2           # カバレッジ
  #   workload_balance: 0.1   # 負荷バランス

# -------------------------------------------------------------------
# データ設定 (config_tokyo23.yamlから継承)
# -------------------------------------------------------------------
data:
  area_restriction:
    enabled: true
    area_name: "東京23区"
    section_code: null
    districts: [
      "千代田区", "中央区", "港区", "新宿区", "文京区", "台東区", 
      "墨田区", "江東区", "品川区", "目黒区", "大田区", "世田谷区", 
      "渋谷区", "中野区", "杉並区", "豊島区", "北区", "荒川区", 
      "板橋区", "練馬区", "足立区", "葛飾区", "江戸川区"
    ]
    # 次元数を明示的に定義
    num_ambulances_in_area: 192
    state_dim: 999  # ハイブリッドモードでも同じ状態空間
    action_dim: 192

  max_steps_per_episode: 3000  
  episode_duration_hours: 24
  
  # 学習期間（軽症系が多い期間と繁忙期の両方を含む）
  train_periods:
    - start_date: "20230701"
      end_date: "20230831"
    - start_date: "20231201"
      end_date: "20240131"

  eval_periods:
    - start_date: "20240701"
      end_date: "20240831"

# -------------------------------------------------------------------
# PPOハイパーパラメータ (軽症系学習に最適化)
# -------------------------------------------------------------------
ppo:
  n_episodes: 5000
  batch_size: 1024
  
  # 学習率
  learning_rate:
    actor: 0.0003
    critic: 0.001
    scheduler: constant
  
  # PPOパラメータ
  n_epochs: 6
  clip_epsilon: 0.1
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.015
  max_grad_norm: 0.5

# -------------------------------------------------------------------
# 報酬設計 (連続的で滑らかな報酬へ改善)
# -------------------------------------------------------------------
reward:
  # システムレベル設定
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
    unhandled_call_penalty: -1.0
  
  # コア報酬設定（ハイブリッド + continuous統合）
  core:
    mode: "hybrid"
    
    # カバレッジ影響重み
    coverage_impact_weight: 0.4
    
    # ===================================================================
    # continuous報酬パラメータ（軽症系のみに適用）
    # 目標時間からの距離に応じた滑らかな報酬関数
    # ===================================================================
    continuous_params:
      # 重症系（直近隊運用なので参考値として保持）
      critical:
        target: 6
        max_bonus: 50.0
        penalty_scale: 5.0
        weight: 5.0
      
      # 中等症（PPO学習対象）
      moderate:
        target: 10 # 改善: 目標を13分から10分に短縮し、より早い到着を促す
        # 廃止: 報酬の飽和を防ぎ、目標時間より早く到着するインセンティブを線形に維持するためコメントアウト
        # max_bonus: 20.0
        penalty_scale: 2.5 # 変更: 目標10分達成のためペナルティスケールを少し強化
        weight: 2.0
      
      # 軽症（PPO学習対象）
      mild:
        target: 10 # 改善: 目標を13分から10分に短縮
        # 廃止: 報酬の飽和を防ぐ
        # max_bonus: 10.0
        penalty_scale: 1.0 # 変更: 中等症よりはペナルティを緩やかにするが、以前(0.5)よりは強化
        weight: 1.0
    
    # ===================================================================
    # hybrid固有パラメータ（カバレッジと負荷バランス）
    # "崖"のある不連続な報酬を廃止し、状態に応じた連続的な報酬に変更
    # ===================================================================
    hybrid_params:
      # --- 新規: 連続的な報酬パラメータ ---
      # 補足: これらの報酬はカバレッジスコア(0-1)や負荷分散スコア(e.g., 1-ジニ係数)に直接掛け合わせることを想定
      coverage_reward_scale: 15.0       # 新規: カバレッジスコアに直接比例した連続的な報酬
      workload_balance_reward_scale: 5.0 # 新規: 負荷分散スコアに直接比例した連続的な報酬
    

    # hybrid_params:
    #   # カバレッジ関連ボーナス/ペナルティ
    #   good_coverage_bonus: 10.0           # カバレッジ0.8以上
    #   coverage_maintenance_bonus: 5.0     # カバレッジ0.6-0.8
    #   poor_coverage_penalty: -10.0        # カバレッジ0.6未満
      
    #   # 負荷バランス関連
    #   balanced_workload_bonus: 2.0        # 均等な負荷分散
    #   overloaded_penalty: -5.0            # 特定救急車の過負荷
      
    #   # 極端な遅延に対する追加ペナルティ（continuous報酬の補完）
    #   over_20min_penalty: -30.0           # 20分超過時の追加ペナルティ
  
  # カバレッジパラメータ（重症系への準備度評価用）
  coverage_params:
    time_threshold_seconds: 360         # 6分（重症系の目標時間）
    drop_penalty_threshold: 0.05        # カバレッジ低下閾値
    drop_penalty_weight: -20.0          # カバレッジ低下ペナルティ
    evaluation_interval: 100            # 100イベントごとに評価
  
  # エピソード報酬
  episode:
    base_penalty_per_minute: -1.0
    achievement_bonuses:
      # 重症系（直近隊運用の結果を評価）
      severe_6min_rate: 50.0            # 重症系6分以内率ボーナス
      critical_6min_rate: 30.0          # 重篤6分以内率ボーナス
      
      # 軽症系（PPO学習の結果を評価）
      mild_13min_rate: 30.0             # 軽症13分以内率ボーナス
      mild_20min_rate: 20.0             # 軽症20分以内率ボーナス
      
      # 全体評価
      rate_13min: 10.0                  # 全体13分以内率
      rate_6min: 20.0                   # 全体6分以内率
    
    failure_penalty_per_incident: -1.0

# -------------------------------------------------------------------
# 教師あり学習 (軽症系のみに適用) - 無効化
# continuousモードでは使用していないため
# -------------------------------------------------------------------
teacher:
  enabled: false
  strategy: closest
  apply_to: ["軽症", "中等症"]
  initial_prob: 0.0
  final_prob: 0.0
  decay_episodes: 2000

# -------------------------------------------------------------------
# ネットワーク設定 (config_tokyo23.yamlから継承)
# -------------------------------------------------------------------
# network:
#   state_encoder:
#     spatial_features: 16
#     temporal_features: 8
#     ambulance_features: 8
#     incident_features: 6
  
  actor:
    hidden_layers: [256, 128]
    activation: relu
    dropout: 0.1
    initialization: xavier_uniform
  
  critic:
    hidden_layers: [256, 128]
    activation: relu
    dropout: 0.1
    init_scale: 0.001

# -------------------------------------------------------------------
# 評価設定 (ハイブリッドモード用メトリクス追加)
# -------------------------------------------------------------------
evaluation:
  interval: 100
  n_eval_episodes: 5
  compare_baselines: ["closest", "severity_based"]
  
  # ハイブリッドモード専用メトリクス
  metrics:
    # 重症系（直近隊運用）
    - "severe_6min_rate"
    - "severe_mean_rt"
    - "critical_6min_rate"
    
    # 軽症系（PPO学習 with continuous reward）
    - "mild_13min_rate"
    - "mild_20min_rate"
    - "mild_mean_rt"
    
    # 全体評価
    - "overall_13min_rate"
    - "overall_mean_rt"
    - "coverage_score"
    - "workload_balance"
    
    # 比較
    - "vs_closest_improvement"
    - "dispatch_ratio"

# -------------------------------------------------------------------
# 学習管理
# -------------------------------------------------------------------
training:
  checkpoint_interval: 250
  keep_last_n: 5
  
  early_stopping:
    enabled: true
    patience: 500
    metric: "mild_20min_rate"
    mode: "min"
    min_delta: 0.001
  
  logging:
    interval: 10              # continuousと同じ頻度
    tensorboard: true
    wandb: true
    wandb_project: "ems_hybrid_continuous_tokyo23"
    
    # ハイブリッドモード用ログ
    hybrid_logs:
      - "severe_dispatch_count"
      - "mild_dispatch_count"
      - "coverage_history"
      - "warning_episodes"
      - "continuous_reward_components"  # continuous報酬の内訳

# -------------------------------------------------------------------
# 重症度カテゴリ設定
# -------------------------------------------------------------------
severity:
  categories:
    critical:
      conditions: ["重症", "重篤", "死亡"]
      reward_weight: 5.0
      time_limit_seconds: 360
    
    moderate:
      conditions: ["中等症"]
      reward_weight: 2.0
      time_limit_seconds: 780
    
    mild:
      conditions: ["軽症"]
      reward_weight: 1.0
      time_limit_seconds: 780
  
  thresholds:
    golden_time: 360
    standard_time: 780

# -------------------------------------------------------------------
# カリキュラム学習 - 無効化
# -------------------------------------------------------------------
curriculum:
  enabled: false
  stages: []