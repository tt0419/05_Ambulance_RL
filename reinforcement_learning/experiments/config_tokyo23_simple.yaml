# PPOå­¦ç¿’è¨­å®šï¼ˆã‚·ãƒ³ãƒ—ãƒ«å ±é…¬ç‰ˆï¼‰
# å¿œç­”æ™‚é–“ã®ã¿ã‚’æœ€é©åŒ–ï¼ˆæœ€é€Ÿãƒ»æœ€ç¢ºå®Ÿï¼‰

experiment:
  name: "ppo_simple_reward"
  description: "ã‚·ãƒ³ãƒ—ãƒ«ãªå ±é…¬è¨­è¨ˆï¼šå¿œç­”æ™‚é–“ã®ã¿ã‚’æœ€å°åŒ–"
  seed: 42
  device: "cuda"

data:
  data_paths:
    grid_mapping: "data/tokyo/processed/grid_mapping_res9.json"
    travel_time_matrix: "data/tokyo/calibration2/linear_calibrated_response.npy"
  
  episode_duration_hours: 24
  exclude_daytime_ambulances: true
  
  area_restriction:
    enabled: true
    area_name: "æ±äº¬23åŒº"
    num_ambulances_in_area: 192
    state_dim: 999
    action_dim: 192
  
  train_periods:
    - start_date: "20230615"
      end_date: "20230621"
  
  eval_periods:
    - start_date: "20230622"
      end_date: "20230622"
  
  max_steps_per_episode: 3000

ppo:
  n_episodes: 200  # ã¾ãš200ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
  batch_size: 1024
  n_epochs: 6
  clip_epsilon: 0.1
  learning_rate:
    actor: 0.0003
    critic: 0.001
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.02  # å°‘ã—å¢—ã‚„ã—ã¦æ¢ç´¢ã‚’ä¿ƒé€²

reward:
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
  
  core:
    mode: "simple"  # ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰
    
    simple_params:
      # ğŸ”¥ ã‚·ãƒ³ãƒ—ãƒ«è¨­è¨ˆï¼šå¿œç­”æ™‚é–“ã®ã¿
      time_penalty_per_minute: -1.0      # 1åˆ† = -1ãƒã‚¤ãƒ³ãƒˆ
      
      # ãƒœãƒ¼ãƒŠã‚¹
      critical_under_6min_bonus: 15.0    # 6åˆ†ä»¥å†…
      moderate_under_13min_bonus: 8.0    # 13åˆ†ä»¥å†…
      mild_under_13min_bonus: 8.0
      
      # ãƒšãƒŠãƒ«ãƒ†ã‚£
      over_13min_penalty: -10.0
      over_20min_penalty: -100.0         # 20åˆ†è¶…éã¯æ¥µç«¯ãªãƒšãƒŠãƒ«ãƒ†ã‚£
      
      # ã‚«ãƒãƒ¬ãƒƒã‚¸ã¯ç„¡è¦–ï¼ˆãƒœãƒ¼ãƒŠã‚¹0ï¼‰
      imitation_bonus: 0.0

# ğŸ”¥ å­¦ç¿’æ™‚ã¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç„¡åŠ¹ï¼ˆå…¨äº‹æ¡ˆã§å­¦ç¿’ï¼‰
hybrid_mode:
  enabled: false

network:
  state_encoder:
    ambulance_features: 8
    incident_features: 6
    spatial_features: 16
    temporal_features: 8
  
  actor:
    hidden_layers: [256, 128]
    activation: "relu"
    dropout: 0.0  # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆç„¡åŠ¹
  
  critic:
    hidden_layers: [256, 128]
    activation: "relu"
    dropout: 0.0

training:
  checkpoint_interval: 50
  keep_last_n: 3
  
  early_stopping:
    enabled: true
    patience: 30
    min_delta: 0.5
  
  logging:
    interval: 50
    tensorboard: true
    wandb: true
    wandb_project: "ems_simple_reward"

evaluation:
  interval: 25  # é »ç¹ã«è©•ä¾¡
  n_eval_episodes: 3
  compare_baselines: ["closest"]
  
  metrics:
    - "overall_mean_rt"
    - "mild_mean_rt"
    - "moderate_mean_rt"
    - "vs_closest_improvement"

# ğŸ”¥ æ¨¡å€£å­¦ç¿’ã‚’å¼·åŠ›ã«æœ‰åŠ¹åŒ–
teacher:
  enabled: true
  strategy: "closest"
  initial_prob: 0.9      # åˆæœŸ90%æ¨¡å€£ï¼ˆã»ã¼æ•™å¸«é€šã‚Šï¼‰
  final_prob: 0.3        # æœ€çµ‚30%æ¨¡å€£
  decay_episodes: 150    # 150ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§æ¸›è¡°
  apply_to: ["è»½ç—‡", "ä¸­ç­‰ç—‡", "é‡ç—‡", "é‡ç¯¤", "æ­»äº¡"]

