# PPO学習設定（修正版 v2）
# 全ての問題を修正

experiment:
  name: "hybrid_ppo_fixed_v2"
  description: "全ての問題を修正：1)学習時ハイブリッド無効, 2)模倣学習有効, 3)報酬内部構造修正"
  seed: 42
  device: "cuda"

data:
  data_paths:
    grid_mapping: "data/tokyo/processed/grid_mapping_res9.json"
    travel_time_matrix: "data/tokyo/calibration2/linear_calibrated_response.npy"
  
  episode_duration_hours: 24
  exclude_daytime_ambulances: true
  
  area_restriction:
    enabled: true
    area_name: "東京23区"
    num_ambulances_in_area: 192
    state_dim: 999
    action_dim: 192
  
  # 1週間分の学習データ
  train_periods:
    - start_date: "20230615"
      end_date: "20230621"
  
  eval_periods:
    - start_date: "20230622"
      end_date: "20230622"
  
  max_steps_per_episode: 3000

ppo:
  n_episodes: 500  # まず500エピソードでテスト
  batch_size: 1024
  n_epochs: 6
  clip_epsilon: 0.1
  learning_rate:
    actor: 0.0003
    critic: 0.001
  gamma: 0.99
  gae_lambda: 0.95
  entropy_coef: 0.015

reward:
  system:
    dispatch_failure: -1.0
    no_available_ambulance: 0.0
  
  core:
    mode: "hybrid"
    
    # 🔥 修正: 報酬内部構造を応答時間重視に変更
    hybrid_params:
      time_penalty_per_minute: -1.0        # -0.1 → -1.0（10倍強化）
      mild_under_13min_bonus: 15.0         # 5.0 → 15.0
      moderate_under_13min_bonus: 20.0     # 10.0 → 20.0
      over_13min_penalty: -20.0            # -5.0 → -20.0（4倍強化）
      over_20min_penalty: -100.0           # -50.0 → -100.0
      
      # カバレッジ報酬を大幅削減
      good_coverage_bonus: 2.0             # 10.0 → 2.0（1/5）
      coverage_maintenance_bonus: 1.0      # 5.0 → 1.0（1/5）
      poor_coverage_penalty: -3.0          # -10.0 → -3.0（1/3）
      
      balanced_workload_bonus: 1.0
      overloaded_penalty: -2.0

# 🔥 修正1: 学習時はハイブリッド無効
hybrid_mode:
  enabled: false  # ← 学習時は全事案で学習
  severity_classification:
    severe_conditions: ["重症", "重篤", "死亡"]
    mild_conditions: ["軽症", "中等症"]
  
  # 推論時の重み（学習には影響しない）
  reward_weights:
    response_time: 0.8    # さらに強化 0.7 → 0.8
    coverage: 0.15        # さらに削減 0.2 → 0.15
    workload_balance: 0.05
  
  time_thresholds:
    good: 13
    warning: 20
  
  penalties:
    over_warning: -100.0
    per_minute_over: -5.0

network:
  state_encoder:
    ambulance_features: 8
    incident_features: 6
    spatial_features: 16
    temporal_features: 8
  
  actor:
    hidden_layers: [256, 128]
    activation: "relu"
    dropout: 0.1
  
  critic:
    hidden_layers: [256, 128]
    activation: "relu"
    dropout: 0.1

training:
  checkpoint_interval: 100
  keep_last_n: 5
  
  early_stopping:
    enabled: true
    patience: 20
    min_delta: 1.0
  
  logging:
    interval: 100
    tensorboard: true
    wandb: true
    wandb_project: "ems_hybrid_fixed_v2"

evaluation:
  interval: 50  # より頻繁に評価
  n_eval_episodes: 5
  compare_baselines: ["closest"]
  
  metrics:
    - "overall_mean_rt"
    - "mild_mean_rt"
    - "moderate_mean_rt"
    - "vs_closest_improvement"

# 🔥 修正2: 模倣学習を有効化
teacher:
  enabled: true              # ← 有効化
  strategy: "closest"        # 直近隊を教師に
  initial_prob: 0.5          # 初期50%模倣
  final_prob: 0.1            # 最終10%模倣
  decay_episodes: 200        # 200エピソードで減衰
  apply_to: ["軽症", "中等症", "重症", "重篤", "死亡"]  # 全事案

