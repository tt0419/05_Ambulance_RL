# å ±é…¬ãŒ0ã«ãªã‚‹å•é¡Œã®ä¿®æ­£

## ğŸ”¥ å•é¡Œã®ç—‡çŠ¶

**å…¨ã¦ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§å ±é…¬ãŒ0.0**
- å­¦ç¿’ãŒå…¨ãé€²ã¾ãªã„
- ãƒ¢ãƒ‡ãƒ«ãŒæ”¹å–„ã—ãªã„

---

## ğŸ” è€ƒãˆã‚‰ã‚Œã‚‹åŸå› 

### åŸå› 1: hybrid_modeãŒèª¤ã£ã¦æœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹

```python
# reinforcement_learning/environment/ems_environment.py: 773-787è¡Œ
if self.hybrid_mode and current_incident:
    severity = current_incident.get('severity', '')
    if severity in self.severe_conditions:
        # å ±é…¬ã¯0ï¼ˆå­¦ç¿’å¯¾è±¡å¤–ï¼‰
        reward = 0.0
```

**ç—‡çŠ¶:**
- å…¨äº‹æ¡ˆãŒé‡ç—‡ç³»ã¨ã—ã¦å‡¦ç†ã•ã‚Œã‚‹
- ã¾ãŸã¯ã€hybrid_modeãŒ true ã«ãªã£ã¦ã„ã‚‹

---

## ğŸš€ ä¿®æ­£æ–¹æ³•ï¼ˆ3ã¤ã®é¸æŠè‚¢ï¼‰

### **ä¿®æ­£1: EMSEnvironmentã®åˆæœŸåŒ–ã‚’å¼·åˆ¶çš„ã«ä¿®æ­£** â­â­â­

**ãƒ•ã‚¡ã‚¤ãƒ«:** `reinforcement_learning/environment/ems_environment.py`

```python
# 239è¡Œç›®ã‚’ä¿®æ­£
# ä¿®æ­£å‰:
self.hybrid_mode = self.config.get('hybrid_mode', {}).get('enabled', False)

# ä¿®æ­£å¾Œ:
hybrid_config = self.config.get('hybrid_mode', {})
self.hybrid_mode = hybrid_config.get('enabled', False)

# ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¿½åŠ 
print(f"[EMSç’°å¢ƒ] hybrid_mode: {self.hybrid_mode}")
if self.hybrid_mode:
    print(f"  severe_conditions: {self.severe_conditions}")
```

---

### **ä¿®æ­£2: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ˜ç¤ºçš„ã«ç¢ºèª**

`config_tokyo23_simple.yaml` ã® hybrid_mode ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¢ºèªï¼š

```yaml
hybrid_mode:
  enabled: false  # â† falseã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèª
```

ã‚‚ã— `enabled: true` ã«ãªã£ã¦ã„ãŸã‚‰ã€`false` ã«å¤‰æ›´ã€‚

---

### **ä¿®æ­£3: å¼·åˆ¶çš„ã«é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆæœ€ã‚‚ç¢ºå®Ÿï¼‰**

**ãƒ•ã‚¡ã‚¤ãƒ«:** `reinforcement_learning/environment/ems_environment.py`

```python
# 773è¡Œç›®ã®ifæ–‡ã‚’ç„¡åŠ¹åŒ–
# ä¿®æ­£å‰:
if self.hybrid_mode and current_incident:
    # ...

# ä¿®æ­£å¾Œ:
if False and self.hybrid_mode and current_incident:  # â† Falseã‚’è¿½åŠ 
    # ...
```

ã“ã‚Œã§ã€hybrid_modeã®è¨­å®šã«é–¢ã‚ã‚‰ãšã€å¸¸ã«é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

---

## ğŸ› ï¸ æ¨å¥¨ä¿®æ­£æ‰‹é †

### Step 1: ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œ

```bash
python debug_reward_issue.py
```

**å‡ºåŠ›ã‚’ç¢ºèª:**
- `hybrid_mode: True` â†’ å•é¡Œã‚ã‚Š
- `hybrid_mode: False` ã ãŒå ±é…¬ãŒ0 â†’ åˆ¥ã®å•é¡Œ

### Step 2: ä¿®æ­£1ã‚’é©ç”¨

```bash
# ems_environment.pyã‚’ç·¨é›†
# 239è¡Œç›®ã«ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ã‚’è¿½åŠ 
```

### Step 3: å†å­¦ç¿’

```bash
python train_ppo.py --config reinforcement_learning/experiments/config_tokyo23_simple.yaml
```

---

## ğŸ“Š ç¢ºèªæ–¹æ³•

### å­¦ç¿’é–‹å§‹æ™‚ã®å‡ºåŠ›ã‚’ç¢ºèª

```
[EMSç’°å¢ƒ] hybrid_mode: False  â† ã“ã‚ŒãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¹ã
[Simpleå ±é…¬] å‚·ç—…åº¦: è»½ç—‡, æ™‚é–“: 8.5åˆ†, å ±é…¬: -2.50  â† å ±é…¬ãŒ0ä»¥å¤–
```

### training_stats.json ã‚’ç¢ºèª

```json
{
  "episode_rewards": [
    -15.3,  â† 0ä»¥å¤–ã®å€¤
    -12.8,
    -18.5,
    ...
  ]
}
```

---

## ğŸ¯ ä¿®æ­£å¾Œã®æœŸå¾…çµæœ

### å­¦ç¿’æ›²ç·š

```
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰10:  å¹³å‡å ±é…¬: -150, å¹³å‡å¿œç­”æ™‚é–“: 15åˆ†
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰50:  å¹³å‡å ±é…¬: -80,  å¹³å‡å¿œç­”æ™‚é–“: 12åˆ†
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰100: å¹³å‡å ±é…¬: -50,  å¹³å‡å¿œç­”æ™‚é–“: 10åˆ†
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰200: å¹³å‡å ±é…¬: -30,  å¹³å‡å¿œç­”æ™‚é–“: 8-9åˆ†
```

---

## ğŸ”§ ç·Šæ€¥å›é¿ç­–

**ã‚‚ã—ä¿®æ­£ã—ã¦ã‚‚ãƒ€ãƒ¡ãªå ´åˆ:**

```python
# reinforcement_learning/environment/ems_environment.py
# 239è¡Œç›®ã‚’ä»¥ä¸‹ã«å®Œå…¨ã«ç½®ãæ›ãˆ

self.hybrid_mode = False  # å¼·åˆ¶çš„ã«False
print("[EMSç’°å¢ƒ] hybrid_mode ã‚’å¼·åˆ¶çš„ã«ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")
```

ã“ã‚Œã§100%é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

---

## ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **ä»Šã™ã**: `debug_reward_issue.py` ã‚’å®Ÿè¡Œ
2. **å•é¡Œç‰¹å®š**: å‡ºåŠ›ã‚’ç¢ºèª
3. **ä¿®æ­£é©ç”¨**: ä¿®æ­£1ã¾ãŸã¯ä¿®æ­£3ã‚’é©ç”¨
4. **å†å­¦ç¿’**: 200ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ
5. **ç¢ºèª**: å ±é…¬ãŒ0ä»¥å¤–ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª

**å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼**

